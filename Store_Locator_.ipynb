{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYX5qXp8rczqL5aawmOQTM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pandeyankitg/web-scrapping-Reliance-Store-details-using-python/blob/main/Store_Locator_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "import json\n",
        "import argparse\n",
        "import traceback\n",
        "import BeautifulSoup\n",
        "\n",
        "def locate_stores(radius):\n",
        "    \"\"\"\n",
        "    Function to locate Reliance Fresh stores\n",
        "    \"\"\"\n",
        "    url = \"https://storelocator.ril.com/\"%radius)\n",
        "    r = requests.get(URL)\n",
        "   \n",
        "soup = BeautifulSoup(r.content, 'html5lib')\n",
        "   \n",
        "    headers = { 'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
        "                'accept-encoding':'gzip, deflate, br',\n",
        "                'accept-language':'en-GB,en;q=0.9,en-US;q=0.8,ml;q=0.7',\n",
        "                'cache-control':'max-age=0',\n",
        "                'upgrade-insecure-requests':'1',\n",
        "                'user-agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36'\n",
        "    }\n",
        "    stores = []\n",
        "    print(\"retrieving stores\")\n",
        "    for retry in range(10):\n",
        "        try:\n",
        "            get_store = requests.get(url, headers=headers, verify=False)\n",
        "            store_response = get_store.json()\n",
        "            stores_data = store_response.get('payload',{}).get(\"storesData\",{}).get(\"stores\",[])\n",
        "            \n",
        "            if not stores_data:\n",
        "                print(\"no stores found near %s\"%(radius))\n",
        "                return []\n",
        "            print(\"processing store details\")\n",
        "            #iterating through all stores\n",
        "            for store in stores_data:\n",
        "                store_name = store.get(\"StoreName\")\n",
        "                address = store.get(\"address\").get(\"address\")\n",
        "                postal_code = store.get(\"address\").get(\"postalCode\")\n",
        "                city = store.get(\"address\").get(\"city\")\n",
        "                phone = store.get(\"phone\")\n",
        "\n",
        "                data = {\n",
        "                        \"name\":display_name,\n",
        "                        \"address\":address,\n",
        "                        \"pin_code\":postal_code,\n",
        "                        \"city\":city,\n",
        "                        \"phone\":phone,\n",
        "                }\n",
        "                stores.append(data)\n",
        "            return stores\n",
        "        except:\n",
        "            print(trackback.format_exc())\n",
        "    \n",
        "    return []   \n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    \n",
        "    argparser = argparse.ArgumentParser()\n",
        "    argparser.add_argument('pin_code',help = 'pin code to search')\n",
        "    args = argparser.parse_args()\n",
        "    zip_code = args.zip_code\n",
        "    scraped_data = locate_stores(zip_code)\n",
        "    \n",
        "    if scraped_data:\n",
        "        print (\"Writing scraped data to %s_stores.csv\"%(zip_code))\n",
        "        with open('%s_stores.csv'%(radius),'wb') as csvfile:\n",
        "            fieldnames = [\"Store Name\",\"City\",\"Address of the Store\",\"Postal Code\",\"Timing\",\"Phone\"]\n",
        "            writer = csv.DictWriter(csvfile,fieldnames = fieldnames,quoting=csv.QUOTE_ALL)\n",
        "            writer.writeheader()\n",
        "            for data in scraped_data:\n",
        "                writer.writerow(data)"
      ],
      "metadata": {
        "id": "MZLdiI1-03y2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}